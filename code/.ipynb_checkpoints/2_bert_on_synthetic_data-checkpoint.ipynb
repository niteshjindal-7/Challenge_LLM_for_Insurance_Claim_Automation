{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc67ef3d",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59af12b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 22:27:38.934467: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import BertModel\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "# from transformers import AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "print(\"Transformer Module Version\", transformers.__version__)\n",
    "# !pip install evaluate\n",
    "import evaluate\n",
    "import os\n",
    "import natsort\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683ce42",
   "metadata": {},
   "source": [
    "## Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ae923c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim Categories: ['property' 'auto' 'health']\n",
      "Training dataset size: 24000\n",
      "Test dataset size: 6000\n",
      "Training data: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14634/113259463.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['encoded_label'] = labelencoder.fit_transform(train['label'])\n",
      "/tmp/ipykernel_14634/113259463.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"encoded_label\"] = labelencoder.transform(test['label'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>policy_num</th>\n",
       "      <th>patient_name</th>\n",
       "      <th>date</th>\n",
       "      <th>policy_claim_no</th>\n",
       "      <th>text</th>\n",
       "      <th>claim_amount</th>\n",
       "      <th>claim_status</th>\n",
       "      <th>communication_history</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21753</th>\n",
       "      <td>auto</td>\n",
       "      <td>151393</td>\n",
       "      <td>Ava Williams</td>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>9433</td>\n",
       "      <td>There wa an incident on 2023-02-15 where Vehic...</td>\n",
       "      <td>2851</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>We need to ass the impact and consequence of t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>health</td>\n",
       "      <td>610541</td>\n",
       "      <td>Elijah Johnson</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>9100</td>\n",
       "      <td>There wa a critical sprain incident on 2023-03...</td>\n",
       "      <td>25912</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>We need to establish preventive measure to avo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22941</th>\n",
       "      <td>property</td>\n",
       "      <td>651336</td>\n",
       "      <td>Mia Martin</td>\n",
       "      <td>2022-10-23</td>\n",
       "      <td>5130</td>\n",
       "      <td>A significant incident took place on 2022-10-2...</td>\n",
       "      <td>94044</td>\n",
       "      <td>Approved</td>\n",
       "      <td>I am seeking reimbursement for the replacement...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>property</td>\n",
       "      <td>721591</td>\n",
       "      <td>Olivia Allen</td>\n",
       "      <td>2023-04-18</td>\n",
       "      <td>7523</td>\n",
       "      <td>A severe [ Property Incident 11 ] took place o...</td>\n",
       "      <td>55573</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>I would appreciate your guidance in understand...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17090</th>\n",
       "      <td>auto</td>\n",
       "      <td>523298</td>\n",
       "      <td>Alexander White</td>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>2030</td>\n",
       "      <td>On 2022-12-07 , a minor collision occurred inv...</td>\n",
       "      <td>57898</td>\n",
       "      <td>Denied</td>\n",
       "      <td>Please gather information on the impact of the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29802</th>\n",
       "      <td>health</td>\n",
       "      <td>851474</td>\n",
       "      <td>Daniel Hall</td>\n",
       "      <td>2022-12-11</td>\n",
       "      <td>1044</td>\n",
       "      <td>There wa a motor vehicle accident on 2022-12-1...</td>\n",
       "      <td>84412</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>I request a thorough investigation into the fa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>property</td>\n",
       "      <td>831608</td>\n",
       "      <td>Sebastian Williams</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>5309</td>\n",
       "      <td>A severe [ Property Incident 30 ] took place o...</td>\n",
       "      <td>65063</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>I request a detailed breakdown of the coverage...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>auto</td>\n",
       "      <td>682288</td>\n",
       "      <td>Ava Davis</td>\n",
       "      <td>2022-07-04</td>\n",
       "      <td>5500</td>\n",
       "      <td>On 2022-07-04 , a minor collision occurred inv...</td>\n",
       "      <td>73324</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>I would like to discus any legal implication o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>auto</td>\n",
       "      <td>645125</td>\n",
       "      <td>James Lee</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>4689</td>\n",
       "      <td>A tree falling incident took place on 2022-08-...</td>\n",
       "      <td>8726</td>\n",
       "      <td>Denied</td>\n",
       "      <td>I request a thorough analysis of the policy an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>property</td>\n",
       "      <td>789355</td>\n",
       "      <td>Benjamin Miller</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>3819</td>\n",
       "      <td>There wa a significant [ Property Incident 17 ...</td>\n",
       "      <td>44084</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>I request a detailed breakdown of the coverage...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label  policy_num        patient_name        date  policy_claim_no  \\\n",
       "21753      auto      151393        Ava Williams  2023-02-15             9433   \n",
       "251      health      610541      Elijah Johnson  2023-03-01             9100   \n",
       "22941  property      651336          Mia Martin  2022-10-23             5130   \n",
       "618    property      721591        Olivia Allen  2023-04-18             7523   \n",
       "17090      auto      523298     Alexander White  2022-12-07             2030   \n",
       "...         ...         ...                 ...         ...              ...   \n",
       "29802    health      851474         Daniel Hall  2022-12-11             1044   \n",
       "5390   property      831608  Sebastian Williams  2023-01-15             5309   \n",
       "860        auto      682288           Ava Davis  2022-07-04             5500   \n",
       "15795      auto      645125           James Lee  2022-08-31             4689   \n",
       "23654  property      789355     Benjamin Miller  2022-11-02             3819   \n",
       "\n",
       "                                                    text  claim_amount  \\\n",
       "21753  There wa an incident on 2023-02-15 where Vehic...          2851   \n",
       "251    There wa a critical sprain incident on 2023-03...         25912   \n",
       "22941  A significant incident took place on 2022-10-2...         94044   \n",
       "618    A severe [ Property Incident 11 ] took place o...         55573   \n",
       "17090  On 2022-12-07 , a minor collision occurred inv...         57898   \n",
       "...                                                  ...           ...   \n",
       "29802  There wa a motor vehicle accident on 2022-12-1...         84412   \n",
       "5390   A severe [ Property Incident 30 ] took place o...         65063   \n",
       "860    On 2022-07-04 , a minor collision occurred inv...         73324   \n",
       "15795  A tree falling incident took place on 2022-08-...          8726   \n",
       "23654  There wa a significant [ Property Incident 17 ...         44084   \n",
       "\n",
       "      claim_status                              communication_history  \\\n",
       "21753  In Progress  We need to ass the impact and consequence of t...   \n",
       "251    In Progress  We need to establish preventive measure to avo...   \n",
       "22941     Approved  I am seeking reimbursement for the replacement...   \n",
       "618    In Progress  I would appreciate your guidance in understand...   \n",
       "17090       Denied  Please gather information on the impact of the...   \n",
       "...            ...                                                ...   \n",
       "29802  In Progress  I request a thorough investigation into the fa...   \n",
       "5390   In Progress  I request a detailed breakdown of the coverage...   \n",
       "860    In Progress  I would like to discus any legal implication o...   \n",
       "15795       Denied  I request a thorough analysis of the policy an...   \n",
       "23654  In Progress  I request a detailed breakdown of the coverage...   \n",
       "\n",
       "       encoded_label  \n",
       "21753              0  \n",
       "251                1  \n",
       "22941              2  \n",
       "618                2  \n",
       "17090              0  \n",
       "...              ...  \n",
       "29802              1  \n",
       "5390               2  \n",
       "860                0  \n",
       "15795              0  \n",
       "23654              2  \n",
       "\n",
       "[24000 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>policy_num</th>\n",
       "      <th>patient_name</th>\n",
       "      <th>date</th>\n",
       "      <th>policy_claim_no</th>\n",
       "      <th>text</th>\n",
       "      <th>claim_amount</th>\n",
       "      <th>claim_status</th>\n",
       "      <th>communication_history</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>property</td>\n",
       "      <td>283620</td>\n",
       "      <td>Charlotte Miller</td>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>4716</td>\n",
       "      <td>An alarming incident involving a shopping mall...</td>\n",
       "      <td>4978</td>\n",
       "      <td>Approved</td>\n",
       "      <td>I am seeking reimbursement for the repair and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22404</th>\n",
       "      <td>health</td>\n",
       "      <td>439665</td>\n",
       "      <td>Charlotte Anderson</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>7540</td>\n",
       "      <td>On 2023-01-17 , Charlotte Anderson encountered...</td>\n",
       "      <td>39122</td>\n",
       "      <td>Pending</td>\n",
       "      <td>Please provide additional information regardin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23397</th>\n",
       "      <td>property</td>\n",
       "      <td>707259</td>\n",
       "      <td>Daniel Williams</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2917</td>\n",
       "      <td>A distressing [ Property Incident 34 ] took pl...</td>\n",
       "      <td>93664</td>\n",
       "      <td>Denied</td>\n",
       "      <td>I need assistance with documenting and itemizi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25058</th>\n",
       "      <td>health</td>\n",
       "      <td>326420</td>\n",
       "      <td>Amelia Allen</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>8716</td>\n",
       "      <td>There wa a significant puncture incident on 20...</td>\n",
       "      <td>90715</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>Kindly provide a detailed account of the healt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>property</td>\n",
       "      <td>741696</td>\n",
       "      <td>Jack Walker</td>\n",
       "      <td>2023-06-02</td>\n",
       "      <td>8965</td>\n",
       "      <td>A distressing incident took place on 2023-06-0...</td>\n",
       "      <td>55454</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>I am writing to report a property incident and...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>property</td>\n",
       "      <td>462779</td>\n",
       "      <td>Charlotte Jackson</td>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>1471</td>\n",
       "      <td>On 2023-01-24 , a critical [ Property Incident...</td>\n",
       "      <td>9732</td>\n",
       "      <td>Approved</td>\n",
       "      <td>I need to submit a property insurance claim du...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14144</th>\n",
       "      <td>health</td>\n",
       "      <td>534443</td>\n",
       "      <td>William Allen</td>\n",
       "      <td>2022-08-21</td>\n",
       "      <td>4690</td>\n",
       "      <td>There wa a car accident incident on 2022-08-21...</td>\n",
       "      <td>7388</td>\n",
       "      <td>Denied</td>\n",
       "      <td>Kindly provide a detailed account of the healt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23108</th>\n",
       "      <td>health</td>\n",
       "      <td>750239</td>\n",
       "      <td>Elijah White</td>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>7323</td>\n",
       "      <td>There wa a heart attack incident on 2022-09-29...</td>\n",
       "      <td>30633</td>\n",
       "      <td>Pending</td>\n",
       "      <td>Kindly provide a detailed account of the healt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25703</th>\n",
       "      <td>auto</td>\n",
       "      <td>252408</td>\n",
       "      <td>Sebastian Jackson</td>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>7733</td>\n",
       "      <td>On 2023-03-12 , Vehicle W encountered a mechan...</td>\n",
       "      <td>59718</td>\n",
       "      <td>Approved</td>\n",
       "      <td>I request a comprehensive report on the auto i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29171</th>\n",
       "      <td>health</td>\n",
       "      <td>372671</td>\n",
       "      <td>Sophia Jackson</td>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>1753</td>\n",
       "      <td>A significant spinal injury incident took plac...</td>\n",
       "      <td>52115</td>\n",
       "      <td>Denied</td>\n",
       "      <td>It is essential to gather all pertinent inform...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label  policy_num        patient_name        date  policy_claim_no  \\\n",
       "2308   property      283620    Charlotte Miller  2023-03-12             4716   \n",
       "22404    health      439665  Charlotte Anderson  2023-01-17             7540   \n",
       "23397  property      707259     Daniel Williams  2023-04-08             2917   \n",
       "25058    health      326420        Amelia Allen  2023-05-08             8716   \n",
       "2664   property      741696         Jack Walker  2023-06-02             8965   \n",
       "...         ...         ...                 ...         ...              ...   \n",
       "2210   property      462779   Charlotte Jackson  2023-01-24             1471   \n",
       "14144    health      534443       William Allen  2022-08-21             4690   \n",
       "23108    health      750239        Elijah White  2022-09-29             7323   \n",
       "25703      auto      252408   Sebastian Jackson  2023-03-12             7733   \n",
       "29171    health      372671      Sophia Jackson  2022-07-15             1753   \n",
       "\n",
       "                                                    text  claim_amount  \\\n",
       "2308   An alarming incident involving a shopping mall...          4978   \n",
       "22404  On 2023-01-17 , Charlotte Anderson encountered...         39122   \n",
       "23397  A distressing [ Property Incident 34 ] took pl...         93664   \n",
       "25058  There wa a significant puncture incident on 20...         90715   \n",
       "2664   A distressing incident took place on 2023-06-0...         55454   \n",
       "...                                                  ...           ...   \n",
       "2210   On 2023-01-24 , a critical [ Property Incident...          9732   \n",
       "14144  There wa a car accident incident on 2022-08-21...          7388   \n",
       "23108  There wa a heart attack incident on 2022-09-29...         30633   \n",
       "25703  On 2023-03-12 , Vehicle W encountered a mechan...         59718   \n",
       "29171  A significant spinal injury incident took plac...         52115   \n",
       "\n",
       "      claim_status                              communication_history  \\\n",
       "2308      Approved  I am seeking reimbursement for the repair and ...   \n",
       "22404      Pending  Please provide additional information regardin...   \n",
       "23397       Denied  I need assistance with documenting and itemizi...   \n",
       "25058  In Progress  Kindly provide a detailed account of the healt...   \n",
       "2664   In Progress  I am writing to report a property incident and...   \n",
       "...            ...                                                ...   \n",
       "2210      Approved  I need to submit a property insurance claim du...   \n",
       "14144       Denied  Kindly provide a detailed account of the healt...   \n",
       "23108      Pending  Kindly provide a detailed account of the healt...   \n",
       "25703     Approved  I request a comprehensive report on the auto i...   \n",
       "29171       Denied  It is essential to gather all pertinent inform...   \n",
       "\n",
       "       encoded_label  \n",
       "2308               2  \n",
       "22404              1  \n",
       "23397              2  \n",
       "25058              1  \n",
       "2664               2  \n",
       "...              ...  \n",
       "2210               2  \n",
       "14144              1  \n",
       "23108              1  \n",
       "25703              0  \n",
       "29171              1  \n",
       "\n",
       "[6000 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = pd.read_csv('insurance_synthetic_data.csv')\n",
    "df  = pd.read_csv('../dataset/insurance_claims_data/insurance_claims.csv')\n",
    "df = df.rename(columns = {'incident_class':'label'})\n",
    "df = df.rename(columns = {'incident_description':'text'})\n",
    "# display(df)\n",
    "print(\"Claim Categories:\", df.label.unique())\n",
    "\n",
    "\n",
    "# Divide the data into train, validation, and test sets\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(\"Training dataset size:\", len(train))\n",
    "print(\"Test dataset size:\", len(test))\n",
    "\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(train['label'])\n",
    "train['encoded_label'] = labelencoder.fit_transform(train['label'])\n",
    "test[\"encoded_label\"] = labelencoder.transform(test['label'])\n",
    "print(\"Training data Examples: \")\n",
    "display(train)\n",
    "print(\"Test data Examples: \")\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0bcfad",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa402815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train encodings shape  torch.Size([24000, 12])\n",
      "test encodings shape  torch.Size([6000, 12])\n"
     ]
    }
   ],
   "source": [
    "# store labels in a list \n",
    "train_labels = torch.tensor(train[\"encoded_label\"].tolist())\n",
    "test_labels = torch.tensor(test[\"encoded_label\"].tolist())\n",
    "\n",
    "# Get the text data as list of incident description \n",
    "train_texts = train[\"text\"].tolist()\n",
    "test_texts = test[\"text\"].tolist()\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    train_texts,\n",
    "    padding=True,           # pad all inputs to max length\n",
    "    max_length=12,         # Bert max is 512, we choose 24 for computational efficiency\n",
    "    return_tensors=\"pt\",    # Return format pytorch tensor\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "print('train encodings shape ', train_encodings['input_ids'].shape)\n",
    "\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    test_texts,\n",
    "    padding=True,           # pad all inputs to max length\n",
    "    max_length=12,         # Bert max is 512, we choose 24 for computational efficiency\n",
    "    return_tensors=\"pt\",    # Return format pytorch tensor\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "print('test encodings shape ', test_encodings['input_ids'].shape)\n",
    "\n",
    "\n",
    "# Convert the tokenized inputs into a PyTorch dataset\n",
    "train_ds = TensorDataset(\n",
    "    train_encodings[\"input_ids\"],\n",
    "    train_encodings[\"attention_mask\"],\n",
    "    train_labels  # Assuming you have the corresponding train labels\n",
    ")\n",
    "\n",
    "\n",
    "# Convert the tokenized inputs into a PyTorch dataset\n",
    "test_ds = TensorDataset(\n",
    "    test_encodings[\"input_ids\"],\n",
    "    test_encodings[\"attention_mask\"],\n",
    "    test_labels  # Assuming you have the corresponding train labels\n",
    ")\n",
    "\n",
    "\n",
    "# Define batch size for the train_loader and test_loader\n",
    "batch_size = 16\n",
    "\n",
    "# Create the train_loader\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Create the test_loader\n",
    "# for i in test_loader:\n",
    "#     print(i)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eadec08",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50777dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Device: NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be17ab755dc4f10a3569086b7580045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average Loss: 0.1199\n",
      "Epoch 2/3, Average Loss: 0.0796\n",
      "Epoch 3/3, Average Loss: 0.0959\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "base_model1 = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "# Get the GPU device on which we run our experiments\n",
    "gpu_name = torch.cuda.get_device_name(device) if device.type == 'cuda' else 'N/A'\n",
    "print(\"GPU Device:\", gpu_name)\n",
    "\n",
    "\n",
    "\n",
    "model1 = base_model1.to(device)\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model1.parameters(), lr=5e-5)\n",
    "\n",
    "# Set the number of epochs and calculate the total training steps\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "\n",
    "# Training loop\n",
    "model1.train()\n",
    "progress_bar = tqdm(total=num_training_steps)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss = 0.0 \n",
    "    \n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model1(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()  # Accumulate the loss\n",
    "#         print('Loss item', loss.item())\n",
    "        \n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_description(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "    avg_loss = epoch_loss / len(train_loader)  # Calculate average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d87be",
   "metadata": {},
   "source": [
    "## Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6928f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      2040\n",
      "           1       1.00      0.87      0.93      1992\n",
      "           2       1.00      0.98      0.99      1968\n",
      "\n",
      "    accuracy                           0.95      6000\n",
      "   macro avg       0.96      0.95      0.95      6000\n",
      "weighted avg       0.96      0.95      0.95      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluation loop\n",
    "model1.eval()\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model1(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Get predicted labels\n",
    "#         _, predicted = torch.max(logits, dim=1)\n",
    "        predicted = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        predictions.extend(predicted.cpu().tolist())\n",
    "        true_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "# Calculate classification report\n",
    "classification_rep = classification_report(true_labels, predictions)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3990b97",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "https://huggingface.co/docs/transformers/training\n",
    "\n",
    "https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84be3394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
