{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59af12b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 15:09:53.807903: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import BertModel\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "# from transformers import AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "print(transformers.__version__)\n",
    "# !pip install evaluate\n",
    "import evaluate\n",
    "import os\n",
    "import natsort\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f17ec608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of common strings 9986\n",
      "filtered_df shape (9986, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>Milk Milk.zip</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>-What are you doing? -you told me to satanize ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>imgflip.com ME 1254 NEW BUGS AFTER CHANGES BUG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>Bedroom Kitchen Bathroom Bron memes storage</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>WAKEUP EARLY FREELANCERS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>15002.jpg</td>\n",
       "      <td>WAITING FOR THE END OF THE COVID  imgflip.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>15003.jpg</td>\n",
       "      <td>SMART WOMEN ARE AROUND  imgflip.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>15004.jpg</td>\n",
       "      <td>GOOD GIRLS ARE BEHIND THE CORNER  imgflip.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>15005.jpg</td>\n",
       "      <td>COOKING FOR MY WIFE  imgflip.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>15006.jpg</td>\n",
       "      <td>LISTEN TOMORROW WILL BE MONDAY imgflip.com FRO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9986 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name                                               text  label\n",
       "0         1.jpg                                      Milk Milk.zip      0\n",
       "1         2.jpg  -What are you doing? -you told me to satanize ...      0\n",
       "2         3.jpg  imgflip.com ME 1254 NEW BUGS AFTER CHANGES BUG...      0\n",
       "3         4.jpg        Bedroom Kitchen Bathroom Bron memes storage      0\n",
       "4         5.jpg                           WAKEUP EARLY FREELANCERS      0\n",
       "...         ...                                                ...    ...\n",
       "9981  15002.jpg      WAITING FOR THE END OF THE COVID  imgflip.com      0\n",
       "9982  15003.jpg                SMART WOMEN ARE AROUND  imgflip.com      0\n",
       "9983  15004.jpg      GOOD GIRLS ARE BEHIND THE CORNER  imgflip.com      0\n",
       "9984  15005.jpg                   COOKING FOR MY WIFE  imgflip.com      0\n",
       "9985  15006.jpg  LISTEN TOMORROW WILL BE MONDAY imgflip.com FRO...      0\n",
       "\n",
       "[9986 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>15001.jpg</td>\n",
       "      <td>G HIS. UNDYING FIDELITY Steve is hot and perfe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>15002.jpg</td>\n",
       "      <td>How limagined myself as a Teacher...... How I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>15004.jpg</td>\n",
       "      <td>WHERE WILL YOU BE WHEN DIARRHEA STRIKE memecen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>15005.jpg</td>\n",
       "      <td>A MAN WITH DREAMS... NEEDS A WOMAN WITH VISION</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>15006.jpg</td>\n",
       "      <td>THIS IS HOW YOUR GIRLFRIEND SEES YOUR FEMALE F...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>17078.jpg</td>\n",
       "      <td>There are multiple reasons to lower your car T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>17079.jpg</td>\n",
       "      <td>MICHELLE OBAMA IS A MAN IGUARANTEE IT makeamem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>17080.jpg</td>\n",
       "      <td>Looks like the airbags deployed 1234498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>17081.jpg</td>\n",
       "      <td>Half woman half horse</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>17082.jpg</td>\n",
       "      <td>We don't mind if a man tries to rape you. G&amp;P ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name                                               text  label\n",
       "436  15001.jpg  G HIS. UNDYING FIDELITY Steve is hot and perfe...      0\n",
       "854  15002.jpg  How limagined myself as a Teacher...... How I ...      0\n",
       "743  15004.jpg  WHERE WILL YOU BE WHEN DIARRHEA STRIKE memecen...      0\n",
       "44   15005.jpg     A MAN WITH DREAMS... NEEDS A WOMAN WITH VISION      0\n",
       "873  15006.jpg  THIS IS HOW YOUR GIRLFRIEND SEES YOUR FEMALE F...      0\n",
       "..         ...                                                ...    ...\n",
       "871  17078.jpg  There are multiple reasons to lower your car T...      0\n",
       "683  17079.jpg  MICHELLE OBAMA IS A MAN IGUARANTEE IT makeamem...      1\n",
       "406  17080.jpg            Looks like the airbags deployed 1234498      0\n",
       "733  17081.jpg                              Half woman half horse      0\n",
       "241  17082.jpg  We don't mind if a man tries to rape you. G&P ...      1\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path=\"/home/nitesh/Documents/MY_THESIS/MAMI\"\n",
    "\n",
    "train_filename=\"training1.csv\"\n",
    "train_data_file=os.path.join(file_path, train_filename)\n",
    "train2 = pd.read_csv(train_data_file, delimiter='\\t')\n",
    "\n",
    "\n",
    "\n",
    "IDs = [] \n",
    "images = []\n",
    "directory = os.path.join(file_path, 'TRAINING')   # directory where we have images \n",
    "filenames = natsort.natsorted(os.listdir(directory))  \n",
    "\n",
    "# get the ids from the images, where images are having three channels; omit images if channels != 3\n",
    "for i, filename in enumerate(filenames):\n",
    "#     print(i, filename)\n",
    "    if filename.endswith(\".jpg\"):\n",
    "#         ID = int(filename[:-4])\n",
    "        ID = filename\n",
    "        pathname = os.path.join(directory, filename)\n",
    "        im = Image.open(pathname)\n",
    "        im = im.resize((224, 224))  # Resize the image to (224, 224)\n",
    "        imnp = np.array(im)\n",
    "        if len(imnp.shape) != 3:\n",
    "#             print(\"This is 1 channel, so we omit it\", imnp.shape, filename)\n",
    "            continue\n",
    "        IDs.append(ID)\n",
    "        images.append(imnp)\n",
    "\n",
    "def get_common_strings(list1, list2):\n",
    "    return list(set(list1) & set(list2))\n",
    "\n",
    "# Example usage\n",
    "list1 = IDs\n",
    "list2 = list(train2.file_name)  #from the text file where we have text description \n",
    "common_strings = get_common_strings(list1, list2)\n",
    "print('len of common strings', len(common_strings))\n",
    "\n",
    "sorted_ids = natsort.natsorted(common_strings)\n",
    "\n",
    "# print(sorted_ids)\n",
    "\n",
    "# Sort the dataframe with natural ordering of the IDs\n",
    "train2['prefix_file_name'] = train2['file_name'].str.extract('(\\d+)').astype(int)\n",
    "# Assuming 'df' is your DataFrame\n",
    "sorted_train_df = train2.sort_values(by='prefix_file_name', ascending=True)\n",
    "sorted_train_df\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'common_strings' is the list of strings\n",
    "# Get the common string values in the column \n",
    "filtered_df = sorted_train_df[sorted_train_df['file_name'].isin(sorted_ids)].reset_index(drop=True)\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print('filtered_df shape', filtered_df.shape)\n",
    "\n",
    "train3 = filtered_df.copy()\n",
    "# print(train3.shape)\n",
    "\n",
    "trainx = train3.rename(columns={'Text Transcription': 'text'})\n",
    "# display(trainx)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### LOAD TEST DATA\n",
    "\n",
    "test_filename=\"Test.csv\"\n",
    "test_data_file=os.path.join(file_path, test_filename)\n",
    "test1 = pd.read_csv(test_data_file, delimiter='\\t')\n",
    "\n",
    "\n",
    "test_labels_filename = 'test_labels.txt'\n",
    "test_lbls_file = os.path.join(file_path, test_labels_filename)\n",
    "test_labels = pd.read_csv(test_lbls_file, \n",
    "                          delimiter='\\t',\n",
    "                          header=None)\n",
    "\n",
    "test_labels.columns = ['file_name', \n",
    "                      \"misogynous\",\n",
    "                       \"shaming\",\n",
    "                       \"stereotype\",\n",
    "                       \"objectification\",\n",
    "                       \"violence\"]\n",
    "\n",
    "merged_test = pd.merge(test1, test_labels, on='file_name', how='inner')\n",
    "\n",
    "\n",
    "# Sort the dataframe with natural ordering of the IDs\n",
    "merged_test['prefix_file_name'] = merged_test['file_name'].str.extract('(\\d+)').astype(int)\n",
    "# Assuming 'df' is your DataFrame\n",
    "merged_test1 = merged_test.sort_values(by='prefix_file_name', ascending=True)\n",
    "merged_test1\n",
    "\n",
    "\n",
    "# # train = train.rename(columns={'Text Transcription': 'text'})\n",
    "test2 = merged_test1.rename(columns={'Text Transcription': 'text'})\n",
    "# test2\n",
    "\n",
    "\n",
    "\n",
    "# ######################################################\n",
    "train = trainx[['file_name', 'text', 'misogynous']]\n",
    "train = train.rename(columns = {'misogynous':'label'})\n",
    "\n",
    "test = test2[['file_name', 'text', 'misogynous']]\n",
    "test = test.rename(columns = {'misogynous':'label'})\n",
    "\n",
    "# train['label'] = train['label'].map({0: 'non_misogyn', 1: 'misogyn'})\n",
    "# test['label'] = test['label'].map({0: 'non_misogyn', 1: 'misogyn'})\n",
    "display(train)\n",
    "display(test)\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Assuming you have two dataframes named train_df and test_df\n",
    "# combined_df = pd.concat([train, test], ignore_index=True)\n",
    "# combined_df = combined_df[['text', 'label']]\n",
    "# display(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac179963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>Milk Milk.zip</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>-What are you doing? -you told me to satanize ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>imgflip.com ME 1254 NEW BUGS AFTER CHANGES BUG...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>Bedroom Kitchen Bathroom Bron memes storage</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>WAKEUP EARLY FREELANCERS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>15002.jpg</td>\n",
       "      <td>WAITING FOR THE END OF THE COVID  imgflip.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>15003.jpg</td>\n",
       "      <td>SMART WOMEN ARE AROUND  imgflip.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>15004.jpg</td>\n",
       "      <td>GOOD GIRLS ARE BEHIND THE CORNER  imgflip.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>15005.jpg</td>\n",
       "      <td>COOKING FOR MY WIFE  imgflip.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>15006.jpg</td>\n",
       "      <td>LISTEN TOMORROW WILL BE MONDAY imgflip.com FRO...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9986 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name                                               text  label  \\\n",
       "0         1.jpg                                      Milk Milk.zip      0   \n",
       "1         2.jpg  -What are you doing? -you told me to satanize ...      0   \n",
       "2         3.jpg  imgflip.com ME 1254 NEW BUGS AFTER CHANGES BUG...      0   \n",
       "3         4.jpg        Bedroom Kitchen Bathroom Bron memes storage      0   \n",
       "4         5.jpg                           WAKEUP EARLY FREELANCERS      0   \n",
       "...         ...                                                ...    ...   \n",
       "9981  15002.jpg      WAITING FOR THE END OF THE COVID  imgflip.com      0   \n",
       "9982  15003.jpg                SMART WOMEN ARE AROUND  imgflip.com      0   \n",
       "9983  15004.jpg      GOOD GIRLS ARE BEHIND THE CORNER  imgflip.com      0   \n",
       "9984  15005.jpg                   COOKING FOR MY WIFE  imgflip.com      0   \n",
       "9985  15006.jpg  LISTEN TOMORROW WILL BE MONDAY imgflip.com FRO...      0   \n",
       "\n",
       "      encoded_label  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "9981              0  \n",
       "9982              0  \n",
       "9983              0  \n",
       "9984              0  \n",
       "9985              0  \n",
       "\n",
       "[9986 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>15001.jpg</td>\n",
       "      <td>G HIS. UNDYING FIDELITY Steve is hot and perfe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>15002.jpg</td>\n",
       "      <td>How limagined myself as a Teacher...... How I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>15004.jpg</td>\n",
       "      <td>WHERE WILL YOU BE WHEN DIARRHEA STRIKE memecen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>15005.jpg</td>\n",
       "      <td>A MAN WITH DREAMS... NEEDS A WOMAN WITH VISION</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>15006.jpg</td>\n",
       "      <td>THIS IS HOW YOUR GIRLFRIEND SEES YOUR FEMALE F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>17078.jpg</td>\n",
       "      <td>There are multiple reasons to lower your car T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>17079.jpg</td>\n",
       "      <td>MICHELLE OBAMA IS A MAN IGUARANTEE IT makeamem...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>17080.jpg</td>\n",
       "      <td>Looks like the airbags deployed 1234498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>17081.jpg</td>\n",
       "      <td>Half woman half horse</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>17082.jpg</td>\n",
       "      <td>We don't mind if a man tries to rape you. G&amp;P ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name                                               text  label  \\\n",
       "436  15001.jpg  G HIS. UNDYING FIDELITY Steve is hot and perfe...      0   \n",
       "854  15002.jpg  How limagined myself as a Teacher...... How I ...      0   \n",
       "743  15004.jpg  WHERE WILL YOU BE WHEN DIARRHEA STRIKE memecen...      0   \n",
       "44   15005.jpg     A MAN WITH DREAMS... NEEDS A WOMAN WITH VISION      0   \n",
       "873  15006.jpg  THIS IS HOW YOUR GIRLFRIEND SEES YOUR FEMALE F...      0   \n",
       "..         ...                                                ...    ...   \n",
       "871  17078.jpg  There are multiple reasons to lower your car T...      0   \n",
       "683  17079.jpg  MICHELLE OBAMA IS A MAN IGUARANTEE IT makeamem...      1   \n",
       "406  17080.jpg            Looks like the airbags deployed 1234498      0   \n",
       "733  17081.jpg                              Half woman half horse      0   \n",
       "241  17082.jpg  We don't mind if a man tries to rape you. G&P ...      1   \n",
       "\n",
       "     encoded_label  \n",
       "436              0  \n",
       "854              0  \n",
       "743              0  \n",
       "44               0  \n",
       "873              0  \n",
       "..             ...  \n",
       "871              0  \n",
       "683              1  \n",
       "406              0  \n",
       "733              0  \n",
       "241              1  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the CSV file\n",
    "# df = pd.read_csv('insurance_synthetic_data.csv')\n",
    "\n",
    "# # Divide the data into train, validation, and test sets\n",
    "# train1, test1 = train_test_split(combined_df, test_size=0.2, random_state=42)\n",
    "# # val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# # Print the sizes of the datasets\n",
    "# print(\"Train set size:\", len(train1))\n",
    "# # print(\"Validation set size:\", len(val_df))\n",
    "# print(\"Test set size:\", len(test1))\n",
    "\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(train['label'])\n",
    "train['encoded_label'] = labelencoder.fit_transform(train['label'])\n",
    "test[\"encoded_label\"] = labelencoder.transform(test['label'])\n",
    "display(train)\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb5a326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train encodings shape  torch.Size([9986, 12])\n",
      "test encodings shape  torch.Size([1000, 12])\n"
     ]
    }
   ],
   "source": [
    "train_labels = torch.tensor(train[\"encoded_label\"].tolist())\n",
    "test_labels = torch.tensor(test[\"encoded_label\"].tolist())\n",
    "\n",
    "# Convert your train text data to a list\n",
    "train_texts = train[\"text\"].tolist()\n",
    "test_texts = test[\"text\"].tolist()\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    train_texts,\n",
    "    padding=True,           # pad all inputs to max length\n",
    "    max_length=12,         # Bert max is 512, we choose 24 for computational efficiency\n",
    "    return_tensors=\"pt\",    # Return format pytorch tensor\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "print('train encodings shape ', train_encodings['input_ids'].shape)\n",
    "\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    test_texts,\n",
    "    padding=True,           # pad all inputs to max length\n",
    "    max_length=12,         # Bert max is 512, we choose 24 for computational efficiency\n",
    "    return_tensors=\"pt\",    # Return format pytorch tensor\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "print('test encodings shape ', test_encodings['input_ids'].shape)\n",
    "\n",
    "\n",
    "# Convert the tokenized inputs into a PyTorch dataset\n",
    "train_ds = TensorDataset(\n",
    "    train_encodings[\"input_ids\"],\n",
    "    train_encodings[\"attention_mask\"],\n",
    "    train_labels  # Assuming you have the corresponding train labels\n",
    ")\n",
    "\n",
    "\n",
    "# Convert the tokenized inputs into a PyTorch dataset\n",
    "test_ds = TensorDataset(\n",
    "    test_encodings[\"input_ids\"],\n",
    "    test_encodings[\"attention_mask\"],\n",
    "    test_labels  # Assuming you have the corresponding train labels\n",
    ")\n",
    "\n",
    "\n",
    "# Define batch size for the train_loader and test_loader\n",
    "batch_size = 16\n",
    "\n",
    "# Create the train_loader\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Create the test_loader\n",
    "# for i in test_loader:\n",
    "#     print(i)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4776c40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af095edec41042958365e3a430b7bf04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Average Loss: 0.5677\n",
      "Epoch 2/8, Average Loss: 0.4051\n",
      "Epoch 3/8, Average Loss: 0.2353\n",
      "Epoch 4/8, Average Loss: 0.1324\n",
      "Epoch 5/8, Average Loss: 0.0910\n",
      "Epoch 6/8, Average Loss: 0.0700\n",
      "Epoch 7/8, Average Loss: 0.0664\n",
      "Epoch 8/8, Average Loss: 0.0522\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "base_model1 = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model1 = base_model1.to(device)\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model1.parameters(), lr=5e-5)\n",
    "\n",
    "# Set the number of epochs and calculate the total training steps\n",
    "num_epochs = 8\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "\n",
    "# Training loop\n",
    "model1.train()\n",
    "progress_bar = tqdm(total=num_training_steps)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss = 0.0 \n",
    "    \n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model1(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()  # Accumulate the loss\n",
    "#         print('Loss item', loss.item())\n",
    "        \n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_description(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "    avg_loss = epoch_loss / len(train_loader)  # Calculate average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dda65c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61       500\n",
      "           1       0.62      0.72      0.67       500\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.64      0.64      0.64      1000\n",
      "weighted avg       0.64      0.64      0.64      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluation loop\n",
    "model1.eval()\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model1(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Get predicted labels\n",
    "#         _, predicted = torch.max(logits, dim=1)\n",
    "        predicted = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        predictions.extend(predicted.cpu().tolist())\n",
    "        true_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "# Calculate classification report\n",
    "classification_rep = classification_report(true_labels, predictions)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef696fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8720f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad371a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d83d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4493f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e325757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b7138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fabe8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa73b531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c03186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa54f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f4908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dbd2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0bf1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3162ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('insurance_synthetic_data.csv')\n",
    "df  = pd.read_csv('insurance_claims.csv')\n",
    "df = df.rename(columns = {'incident_class':'label'})\n",
    "df = df.rename(columns = {'incident_description':'text'})\n",
    "display(df)\n",
    "print(df.label.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8395d485",
   "metadata": {},
   "source": [
    "## Train Test Split and Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20904133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the CSV file\n",
    "# df = pd.read_csv('insurance_synthetic_data.csv')\n",
    "\n",
    "# Divide the data into train, validation, and test sets\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(\"Train set size:\", len(train))\n",
    "# print(\"Validation set size:\", len(val_df))\n",
    "print(\"Test set size:\", len(test))\n",
    "\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(train['label'])\n",
    "train['encoded_label'] = labelencoder.fit_transform(train['label'])\n",
    "test[\"encoded_label\"] = labelencoder.transform(test['label'])\n",
    "display(train)\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf7ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = torch.tensor(train[\"encoded_label\"].tolist())\n",
    "test_labels = torch.tensor(test[\"encoded_label\"].tolist())\n",
    "\n",
    "# Convert your train text data to a list\n",
    "train_texts = train[\"text\"].tolist()\n",
    "test_texts = test[\"text\"].tolist()\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    train_texts,\n",
    "    padding=True,           # pad all inputs to max length\n",
    "    max_length=20,         # Bert max is 512, we choose 24 for computational efficiency\n",
    "    return_tensors=\"pt\",    # Return format pytorch tensor\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "print('train encodings shape ', train_encodings['input_ids'].shape)\n",
    "\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    test_texts,\n",
    "    padding=True,           # pad all inputs to max length\n",
    "    max_length=20,         # Bert max is 512, we choose 24 for computational efficiency\n",
    "    return_tensors=\"pt\",    # Return format pytorch tensor\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "print('test encodings shape ', test_encodings['input_ids'].shape)\n",
    "\n",
    "\n",
    "# Convert the tokenized inputs into a PyTorch dataset\n",
    "train_ds = TensorDataset(\n",
    "    train_encodings[\"input_ids\"],\n",
    "    train_encodings[\"attention_mask\"],\n",
    "    train_labels  # Assuming you have the corresponding train labels\n",
    ")\n",
    "\n",
    "\n",
    "# Convert the tokenized inputs into a PyTorch dataset\n",
    "test_ds = TensorDataset(\n",
    "    test_encodings[\"input_ids\"],\n",
    "    test_encodings[\"attention_mask\"],\n",
    "    test_labels  # Assuming you have the corresponding train labels\n",
    ")\n",
    "\n",
    "\n",
    "# Define batch size for the train_loader and test_loader\n",
    "batch_size = 16\n",
    "\n",
    "# Create the train_loader\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Create the test_loader\n",
    "# for i in test_loader:\n",
    "#     print(i)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "base_model1 = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model1 = base_model1.to(device)\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model1.parameters(), lr=5e-5)\n",
    "\n",
    "# Set the number of epochs and calculate the total training steps\n",
    "num_epochs = 5\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "\n",
    "# Training loop\n",
    "model1.train()\n",
    "progress_bar = tqdm(total=num_training_steps)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss = 0.0 \n",
    "    \n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model1(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()  # Accumulate the loss\n",
    "#         print('Loss item', loss.item())\n",
    "        \n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_description(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "    avg_loss = epoch_loss / len(train_loader)  # Calculate average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d95b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluation loop\n",
    "model1.eval()\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model1(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Get predicted labels\n",
    "#         _, predicted = torch.max(logits, dim=1)\n",
    "        predicted = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        predictions.extend(predicted.cpu().tolist())\n",
    "        true_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "# Calculate classification report\n",
    "classification_rep = classification_report(true_labels, predictions)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921eeeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "# Evaluation loop\n",
    "model1.eval()\n",
    "\n",
    "# predictions = []\n",
    "# true_labels = []\n",
    "\n",
    "# Disable gradient calculation\n",
    "# with torch.no_grad():\n",
    "for batch in test_loader:\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    labels = labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outputs = model1(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    predicted = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predicted, references=labels)\n",
    "\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b5981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a486fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a579d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d13bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1efcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458439f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be16c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1a082c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9b4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb7993e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f109e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474b971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c668d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7cc202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70035e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from transformers import BertModel\n",
    "\n",
    "# # Load pre-trained BERT model\n",
    "# base_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fd5031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from transformers import BertModel\n",
    "\n",
    "# # Load pre-trained BERT model\n",
    "# base_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # Freeze all the base model's parameters, including embeddings\n",
    "# for param in base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "    \n",
    "\n",
    "# # Define your classification layer\n",
    "# num_classes = 2\n",
    "# classification_layer = nn.Linear(base_model.config.hidden_size, num_classes)\n",
    "\n",
    "\n",
    "# # Create a new model with the classification layer on top of the base model\n",
    "# class ModelWithClassifier(nn.Module):\n",
    "#     def __init__(self, base_model, classification_layer):\n",
    "#         super(ModelWithClassifier, self).__init__()\n",
    "#         self.base_model = base_model\n",
    "#         self.classification_layer = classification_layer\n",
    "\n",
    "#     def forward(self, inputs, attention_mask):\n",
    "#         outputs = self.base_model(inputs, attention_mask=attention_mask)\n",
    "# #         pooled_output = outputs.pooler_output  # Use pooled_output for classification\n",
    "# #         logits = self.classification_layer(pooled_output)\n",
    "#         last_hidden_state = outputs.last_hidden_state\n",
    "#         logits = self.classification_layer(last_hidden_state[:, 0, :])  # Select first token [CLS]\n",
    "#         return logits\n",
    "\n",
    "# model = ModelWithClassifier(base_model, classification_layer)\n",
    "\n",
    "# # Set the device for training\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Define your loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(classification_layer.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b7cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import torch\n",
    "# # import numpy as np\n",
    "\n",
    "# # # Set the random seed for PyTorch\n",
    "# # torch.manual_seed(42)\n",
    "# # torch.backends.cudnn.deterministic = True\n",
    "# # torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# # # Set the random seed for NumPy\n",
    "# # np.random.seed(42)\n",
    "\n",
    "# for inputs, attention_masks, labels in train_loader:\n",
    "#     inputs = inputs.to(device)\n",
    "#     attention_masks = attention_masks.to(device)\n",
    "#     labels = labels.to(device)\n",
    "\n",
    "#     # Forward pass\n",
    "# #     logits = model(inputs, attention_mask=attention_masks)\n",
    "#     logits = model.forward(inputs, attention_mask=attention_masks)\n",
    "#     print(logits)\n",
    "\n",
    "#     # Compute the loss and perform backpropagation\n",
    "#     loss = criterion(logits, labels)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8157890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()  # Set the model to evaluation mode\n",
    "# total_correct = 0\n",
    "# total_samples = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for inputs, attention_masks, labels in test_loader:\n",
    "#         inputs = inputs.to(device)\n",
    "#         attention_masks = attention_masks.to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         # Forward pass\n",
    "#         logits = model.forward(inputs, attention_mask=attention_masks)\n",
    "#         _, predictions = torch.max(logits, dim=1)\n",
    "#         print(\"Predictions:\", predictions)\n",
    "#         print('Labels:', labels)\n",
    "\n",
    "\n",
    "# #         # Update evaluation metrics\n",
    "# #         total_correct += (predictions == labels).sum().item()\n",
    "# #         total_samples += labels.size(0)\n",
    "\n",
    "# # accuracy = total_correct / total_samples\n",
    "# # print(\"Test Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053f71f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec866c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cc2d749",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/training\n",
    "https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
    "\n",
    "https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
