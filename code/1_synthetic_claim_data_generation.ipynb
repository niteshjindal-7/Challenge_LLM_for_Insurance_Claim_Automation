{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4986845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nitesh/Desktop/Challenge_LLM_for_Insurance_Claim_Automation/code'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f79f339",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "class InsuranceClaimGenerator:\n",
    "    def __init__(self, faker_generator=fake):\n",
    "        self.fake = faker_generator\n",
    "\n",
    "\n",
    "    def load_templates(self, template_type, claim_type):\n",
    "        templates = []\n",
    "        file_name = f\"../dataset/templates/{template_type}_templates_{claim_type}.txt\"\n",
    "        with open(file_name, 'r') as file:\n",
    "            template = ''\n",
    "            for line in file:\n",
    "                if line.startswith('['):\n",
    "                    if template:\n",
    "                        templates.append(template.strip())\n",
    "                    template = ''\n",
    "                else:\n",
    "                    template += line\n",
    "        return templates\n",
    "\n",
    "    def generate_insurance_claim(self):\n",
    "        incident_class = random.choice([\"Auto\", \"Health\", \"Property\"])\n",
    "        incident_class = incident_class.lower()\n",
    "        policy_num = self.fake.random_int(100000, 999999)\n",
    "        incident_date = str(self.fake.date_time_between(start_date=\"-1y\", end_date=\"now\").date())\n",
    "        policy_claim_no = self.fake.random_int(1000, 9999)\n",
    "        claim_amount = random.randint(1000, 100000)\n",
    "        claim_status = random.choice([\"Pending\", \"In Progress\", \"Approved\", \"Denied\"])\n",
    "\n",
    "        patient_name, incident_description = self.generate_incident_summary(incident_date, incident_class)\n",
    "\n",
    "        communication_history = self.generate_communication_history(incident_description, incident_class)\n",
    "\n",
    "        return {\n",
    "            \"incident_class\": incident_class,\n",
    "            \"policy_num\": policy_num,\n",
    "            \"patient_name\": patient_name,\n",
    "            \"date\": incident_date,\n",
    "            \"policy_claim_no\": policy_claim_no,\n",
    "            \"incident_description\": incident_description,\n",
    "            \"claim_amount\": claim_amount,\n",
    "            \"claim_status\": claim_status,\n",
    "            \"communication_history\": communication_history,\n",
    "        }\n",
    "\n",
    "    def generate_incident_summary(self, date, incident_type):\n",
    "        incident_template = random.choice(self.load_templates('incident', incident_type))\n",
    "\n",
    "        replacements = {\n",
    "            'vehicle': random.choice([\"car\", \"motorcycle\", \"truck\", \"bus\", \"bicycle\", \"scooter\", \"RV\", \"boat\", \"train\", \"airplane\"]),\n",
    "            'action': random.choice([\"collided\", \"crashed\", \"rammed into\", \"rear-ended\", \"swerved into\", \"skidded into\"]),\n",
    "            'damage': random.choice([\"minor damage\", \"significant damage\", \"extensive damage\", \"total loss\", \"structural damage\", \"cosmetic damage\", \"mechanical damage\", \"electrical damage\"]),\n",
    "            'location': random.choice([\"on a busy street\", \"at an intersection\", \"near a parking lot\", \"in a residential area\", \"on a highway\", \"in a construction zone\", \"in a tunnel\", \"in a parking garage\"]),\n",
    "            'property_class': random.choice([\"house\", \"apartment building\", \"office building\", \"shopping mall\", \"hotel\", \"restaurant\", \"warehouse\", \"farm\", \"museum\", \"church\", \"theater\", \"school\", \"hospital\", \"library\"]),\n",
    "            'cause': random.choice([\"fire\", \"flood\", \"vandalism\", \"earthquake\", \"storm\", \"explosion\", \"theft\", \"structural failure\", \"power outage\", \"pipe burst\"]),\n",
    "            'injury_type': random.choice([\"fracture\", \"burn\", \"concussion\", \"laceration\", \"sprain\", \"bruise\", \"dislocation\", \"strain\", \"puncture\", \"whiplash\", \"head injury\", \"spinal injury\", \"internal injury\"]),\n",
    "            'vehicle_name': random.choice(  [ \"Vehicle A\",    \"Vehicle B\",    \"Vehicle C\",    \"Vehicle D\",    \"Vehicle E\",    \"Vehicle F\",    \"Vehicle G\",    \"Vehicle H\",    \"Vehicle I\",    \"Vehicle J\",    \"Vehicle K\",    \"Vehicle L\",    \"Vehicle M\",    \"Vehicle N\",    \"Vehicle O\",    \"Vehicle P\",    \"Vehicle Q\",    \"Vehicle R\",    \"Vehicle S\",    \"Vehicle T\",    \"Vehicle U\",    \"Vehicle V\",    \"Vehicle W\",    \"Vehicle X\",    \"Vehicle Y\",    \"Vehicle Z\"]),\n",
    "            'date': date,\n",
    "            'medications' : random.choice( [\"ibuprofen\",    \"amoxicillin\",    \"paracetamol\",    \"aspirin\",    \"metformin\",    \"levothyroxine\",    \"simvastatin\",    \"lisinopril\",    \"omeprazole\",    \"atorvastatin\",    \"prednisone\",    \"citalopram\",    \"metoprolol\",    \"fluoxetine\",    \"gabapentin\",    \"tramadol\",    \"pantoprazole\",    \"sertraline\",    \"losartan\",    \"azithromycin\"]),\n",
    "            'patient_name': self.generate_patient_name(),\n",
    "            'class_name': incident_type,\n",
    "        }\n",
    "\n",
    "        incident_template = re.sub(r'\\[(.*?)\\]', lambda match: replacements.get(match.group(1), match.group(0)), incident_template)\n",
    "        incident_template = self.paraphrase_sentence(incident_template)\n",
    "\n",
    "        return replacements['patient_name'], incident_template\n",
    "\n",
    "    def generate_patient_name(self):\n",
    "        first_names = [\"Emma\", \"Liam\", \"Olivia\", \"Noah\", \"Ava\", \"Isabella\", \"Sophia\", \"Mia\", \"Charlotte\", \"Amelia\", \"Elijah\", \"James\", \"Benjamin\", \"Lucas\", \"Henry\", \"Alexander\", \"Sebastian\", \"Jack\", \"William\", \"Daniel\"]\n",
    "        last_names = [\"Smith\", \"Johnson\", \"Williams\", \"Jones\", \"Brown\", \"Davis\", \"Miller\", \"Wilson\", \"Moore\", \"Taylor\", \"Anderson\", \"Thomas\", \"Jackson\", \"White\", \"Harris\", \"Martin\", \"Lee\", \"Walker\", \"Hall\", \"Allen\"]\n",
    "\n",
    "        first_name = random.choice(first_names)\n",
    "        last_name = random.choice(last_names)\n",
    "        return f\"{first_name} {last_name}\"\n",
    "\n",
    "    def generate_communication_history(self, incident_description, incident_type):\n",
    "        communication_template = random.choice(self.load_templates('communication', incident_type))\n",
    "        communication_template = communication_template.replace('[incident_description]', incident_description)\n",
    "        return self.paraphrase_sentence(communication_template)\n",
    "\n",
    "    def paraphrase_sentence(self, sentence):\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        paraphrased_sentence = []\n",
    "        lemmatizer = nltk.WordNetLemmatizer()\n",
    "        for word in tokens:\n",
    "            paraphrased_word = lemmatizer.lemmatize(word)\n",
    "            paraphrased_sentence.append(paraphrased_word)\n",
    "        paraphrased_sentence = ' '.join(paraphrased_sentence)\n",
    "        return paraphrased_sentence\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    insurance_claims=[]\n",
    "    for _ in range(30000):\n",
    "        insurance_claim = InsuranceClaimGenerator().generate_insurance_claim()\n",
    "        \n",
    "#         insurance_claim = json.dumps(insurance_claim, indent=4)\n",
    "        insurance_claims.append(insurance_claim)\n",
    "        \n",
    "\n",
    "    df = pd.DataFrame(insurance_claims)\n",
    "\n",
    "    # Save the DataFrame as a CSV file\n",
    "    df.to_csv('../dataset/insurance_claims_data/insurance_claims.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9e7ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the JSON data to a DataFrame\n",
    "# df = pd.DataFrame(insurance_claims)\n",
    "\n",
    "# # Save the DataFrame as a CSV file\n",
    "# df.to_csv('./insurance_claims.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3425ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# df  = pd.read_csv('insurance_claims.csv')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd291e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['incident_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e079c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
